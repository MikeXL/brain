{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iris Using PyMapD and XGBoost\n",
    "\n",
    "This dataset is brought to you by [UCI Machine Learning Repository](http://archive.ics.uci.edu/ml/), and is sourced form [kaggle](https://www.kaggle.com/uciml/iris/data). It includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n",
    "\n",
    "We will be leveraging MapD, Pygdf and XGBoost for performing predective modelling on the dataset usind the belo steps:\n",
    "\n",
    "1) Get the data. Load it into MapD\n",
    "\n",
    "2) Extract data from MapD into Pygdf\n",
    "\n",
    "3) Train and validate xgboost model\n",
    "\n",
    "4) Use the trained model for prediction\n",
    "\n",
    "5) Store and see predicted values from MapD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pymapd\n",
    "import pygdf\n",
    "from sklearn import datasets\n",
    "from pprint import pprint\n",
    "PWD = \"HyperInteractive\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset into MapD database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                     columns= iris['feature_names'] + ['target'])\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect mapd\n",
    "dbname    = 'mapd'\n",
    "username  = 'mapd'\n",
    "password  = 'HyperInteractive'\n",
    "hostname  = 'localhost'\n",
    "mport     = 9091\n",
    "\n",
    "con = pymapd.connect(user=username,\n",
    "                password=password,\n",
    "                host=hostname,\n",
    "                dbname=dbname,\n",
    "                port=mport)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = 'iris'\n",
    "_create = '''CREATE TABLE {}(sepal_length double, sepal_width double, petal_length double, petal_width double, target int)'''.format(table)\n",
    "_drop = '''DROP TABLE IF EXISTS {}'''.format(table)\n",
    "con.execute(_drop)\n",
    "con.execute(_create)\n",
    "# load data\n",
    "con.load_table(table, df.itertuples(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MapD to Pygdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'query' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-fde60bdc79a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mquery\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'query' is not defined"
     ]
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = '''Select * from {}'''.format(table)\n",
    "#df = con.select_ipc_gpu(query)\n",
    "df = con.select_ipc(query)\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate labels\n",
    "df_y = df['target']\n",
    "del df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpu to DMatrices\n",
    "#dtrain = xgb.DMatrix(df.to_pandas(), label=df_y.to_pandas())\n",
    "dtrain = xgb.DMatrix(df, label=df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3, \n",
    "    'tree_method': 'gpu_hist'\n",
    " \n",
    "}  # the number of classes that exist in this datset\n",
    "num_round = 20  # the number of training iterations\n",
    "ear_stop = 20\n",
    "cv_folds = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation\n",
    "cvresult = xgb.cv(\n",
    "            params=params,\n",
    "            dtrain=dtrain,\n",
    "            num_boost_round=num_round,\n",
    "            nfold=cv_folds,\n",
    "            early_stopping_rounds=ear_stop,\n",
    "            show_stdv=True)\n",
    "\n",
    "cvtest = cvresult['test-merror-mean'].min()\n",
    "cvtrain = cvresult['train-merror-mean'].min()\n",
    "cvtestsd = cvresult['test-merror-std'].min()\n",
    "cvtrainsd = cvresult['train-merror-std'].min()\n",
    "\n",
    "print('CV train loss mean: {}'.format(cvtrain))\n",
    "print('CV train loss std: {}'.format(cvtrainsd))\n",
    "print('CV test loss mean: {}'.format(cvtest))\n",
    "print('CV test loss std: {}'.format(cvtestsd))\n",
    "\n",
    "# Train\n",
    "mod = xgb.train(params, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import plot_importance\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize']= [15,12]\n",
    "matplotlib.rcParams['figure.dpi']= 55\n",
    "plot_importance(mod)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = mod.predict(dtrain)\n",
    "pred_val = np.asarray([np.argmax(line) for line in pred])\n",
    "pred_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
