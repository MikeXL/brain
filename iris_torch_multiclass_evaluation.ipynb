{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multiclass classifier evaluation #\n",
    "\n",
    "A bit tongue twist to read, perhaps call it multi label classifier or multi target classifier.. anywhoo, like multi class classifier. Fun\n",
    "\n",
    "Here comes some thoughts on evaluate 'em\n",
    "\n",
    "1. confusion matrix, good old friend\n",
    "2. cross entropy\n",
    "3. micro vs. macro F1\n",
    "4. ROC .. yes, you hear it.. one-vs-rest still function, be cautious though.. and for three class, there is an 3D version of it. 4D for four class, other than tongue twist, brain twist is required\n",
    "5. Lift, Gain?\n",
    "6. Calibration, K-S ?\n",
    "\n",
    "P.S. None of these would not make sense, if not for model comparison purpose, be it comparing to the hypothetical 50-50 draw or an baseline regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(reticulate)\n",
    "use_python('/PYTHON_SERVICES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch = import(\"torch\")\n",
    "nn    = import(\"torch.nn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = nn$Sequential( nn$Linear(4L, 13L), \n",
    "                  nn$ReLU(),\n",
    "                  nn$Linear(13L, 3L),\n",
    "                  nn$Softmax()\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=3, bias=True)\n",
       "  (3): Softmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx <- sample(1:nrow(iris), 30)\n",
    "train <- iris[-idx, ]\n",
    "test <- iris[idx,]\n",
    "# new.data <- matrix(scale(test[,1:4]), nrow=20, ncol=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30, 4])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_train <- torch$from_numpy(as.matrix(iris[-idx, 1:4]))$float()\n",
    "x_val   <- torch$from_numpy(as.matrix(iris[ idx, 1:4]))$float()\n",
    "x_train$size()\n",
    "x_val$size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train <- torch$from_numpy(as.matrix(as.integer(iris[-idx,5])-1))$long()\n",
    "y_train <- torch$squeeze(y_train, 1L)\n",
    "y_val   <- torch$from_numpy(as.matrix(as.integer(iris[idx,5])-1))$long()\n",
    "y_val   <- torch$squeeze(y_val, 1L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([30])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train$size()\n",
    "y_val$size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "main <- py_run_string(\"\n",
    "def init_weight(m):\n",
    "    #print m.__class__.__name__\n",
    "    if isinstance(m, nn.Linear):\n",
    "        #nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        #nn.init.constant_(m.bias.data, 0)\n",
    "        m.reset_parameters()\n",
    "        #print m.weight.data, m.bias.data\n",
    "\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=3, bias=True)\n",
       "  (3): Softmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m$apply(main$init_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "EPOCH = 500\n",
    "losses = matrix(0, nrow=EPOCH, ncol=2)\n",
    "\n",
    "optim    <- torch$optim$Adam(m$parameters(), lr=.001)\n",
    "\n",
    "for( e in 1:EPOCH)\n",
    "{\n",
    "        m$train()\n",
    "        optim$zero_grad()\n",
    "        yhat = m(x_train)\n",
    "        # print(yhat)\n",
    "        #l = nn$MSELoss()(yhat, y$float())\n",
    "        l = nn$CrossEntropyLoss()(yhat, y_train)\n",
    "        losses[e, 1] = l$item()\n",
    "        l$backward()\n",
    "        optim$step()\n",
    "\n",
    "        #torch$no_grad() \n",
    "        #torch$set_grad_enabled(F)\n",
    "        m$eval()\n",
    "        pred = m(x_val)\n",
    "        ll = nn$CrossEntropyLoss()(pred, y_val)\n",
    "        losses[e,2] = ll$item()\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "       V1               V2        \n",
       " Min.   :0.7479   Min.   :0.8092  \n",
       " 1st Qu.:0.8064   1st Qu.:0.8901  \n",
       " Median :0.8761   Median :0.9896  \n",
       " Mean   :0.9054   Mean   :0.9851  \n",
       " 3rd Qu.:1.0110   3rd Qu.:1.0889  \n",
       " Max.   :1.1294   Max.   :1.1538  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "summary(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlgAAAFoCAMAAAC8KnXeAAAANlBMVEUAAAAA/wBNTU1oaGh8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\nRK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "options(repr.plot.width = 5, repr.plot.height = 3)\n",
    "plot(losses[,1], type=\"l\", col=\"green\", xlab=\"\", ylab=\"\")\n",
    "lines(losses[,2], col=\"grey\", type=\"l\", lty=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=4, out_features=13, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=13, out_features=3, bias=True)\n",
       "  (3): Softmax()\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m$eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_train <- m(x_train)\n",
    "p_val   <- m(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_class_train <- torch$max(p_train$data, 1L)\n",
    "pred_class_val   <- torch$max(p_val$data, 1L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1  2\n",
       "  0 41  0  0\n",
       "  1  0 28  0\n",
       "  2  0  8 43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pred_class_train[[2]]$numpy(), y_train$numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   \n",
       "     0  1  2\n",
       "  0  9  0  0\n",
       "  1  0 10  0\n",
       "  2  0  4  7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "table(pred_class_val[[2]]$numpy(), y_val$numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
